{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lol' 'ol' 'atl' 'tle' 'lea']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np #importa a biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd #importa a biblioteca usada para trabalhar com dataframes\n",
    "import util\n",
    "from scipy.sparse import bsr_matrix\n",
    "\n",
    "#importa o arquivo e extrai as features\n",
    "Xfeatures, Y = util.extract_features('datasets/everything.csv', rep='ngrams',n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svmutil\n",
    "from svmutil import svm_read_problem\n",
    "from svmutil import svm_problem\n",
    "from svmutil import svm_parameter\n",
    "from svmutil import svm_train\n",
    "from svmutil import svm_predict\n",
    "from svmutil import svm_save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de dados de validação: 444\n",
      "Accuracy = 81.7568% (363/444) (classification)\n"
     ]
    }
   ],
   "source": [
    "### Classificador - Kernel linear ###\n",
    "\n",
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "Xk, Yk = Xfeatures[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "# define a porcentagem de dados que irao compor o conjunto de treinamento\n",
    "pTrain = 0.8 \n",
    "\n",
    "# obtem os indices dos dados da particao de treinamento e da particao de teste\n",
    "train_index, test_index = util.stratified_holdOut(Yk, pTrain)\n",
    "\n",
    "X_train, X_test = Xk[train_index, :], Xk[test_index, :];\n",
    "Y_train, Y_test = Yk[train_index], Yk[test_index];\n",
    "\n",
    "train_index, val_index = util.stratified_holdOut(Y_train, pTrain)\n",
    "\n",
    "Xtrain, Xvalid = X_train[train_index, :], X_train[val_index, :]\n",
    "Ytrain, Yvalid = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "\n",
    "\n",
    "print('Numero de dados de validação: %d' %(Xvalid.shape[0]))\n",
    "\n",
    "# Treinamento:\n",
    "custo = 26.0\n",
    "kernel = 0 # kernel linear\n",
    "model = svm_train(Ytrain, Xtrain, '-c %f -t %d' %(custo, kernel))\n",
    "\n",
    "# Predição:\n",
    "p_labs, p_acc, p_vals = svm_predict(Yvalid, bsr_matrix(Xvalid), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(X, Y, Xval, Yval, kernel):\n",
    "    \"\"\"\n",
    "    Retorna o melhor valor para os parâmetros custo e gamma do SVM radial.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    X : matriz com os dados de treinamento\n",
    "    \n",
    "    y : vetor com classes de cada dados de treinamento\n",
    "    \n",
    "    Xval : matriz com os dados de validação\n",
    "    \n",
    "    yval : vetor com as classes dos dados de validação\n",
    "    \n",
    "    Retorno\n",
    "    -------\n",
    "    custo, gamma : os melhores valores para os parêmetros custo e gamma.\n",
    "    \n",
    "     \"\"\"\n",
    "    \n",
    "    #inicializa as variáveis que deverão ser retornadas pela função\n",
    "    custo = 1000\n",
    "    gamma = 1000\n",
    "    \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Complete esta função para retornar os melhores valores de C e gamma com base\n",
    "    # nos dados do conjunto de validação.\n",
    "    # Você pode usar a função svm_predict() para fazer a predição das classes das amostras do\n",
    "    # conjunto de validação. \n",
    "    #\n",
    "    # Importante\n",
    "    # ----\n",
    "    # Você pode calcular a acurácia usando\n",
    "    # \n",
    "    #    acuracia = np.sum(classes==Yval)/len(Yval) \n",
    "    \n",
    "    aux = [0.01,0.1,1,10,100]\n",
    "    values = []\n",
    "    acc = 0\n",
    "    \n",
    "    for i in range(1,9):\n",
    "        for number in aux:\n",
    "            values.append(i * number)\n",
    "    values.sort()\n",
    "    \n",
    "    # Kernel linear\n",
    "    if(kernel == 0):\n",
    "        for aux_custo in values:\n",
    "            model = svm_train(Ytrain, Xtrain, '-c %f -t %d -q' %(aux_custo, kernel))\n",
    "            p_labs, p_acc, p_vals = svm_predict(Yval, Xval, model)\n",
    "\n",
    "            if(p_acc[0] > acc):\n",
    "                acc = p_acc[0]\n",
    "                custo = aux_custo\n",
    "    \n",
    "    # Lista de valores testados para 'custo' e 'gamma' foram escolhidos com base no artigo:\n",
    "    # https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n",
    "    \n",
    "    if(kernel == 1 or kernel == 2):\n",
    "        for i in range (-5, 10, 2):\n",
    "            for j in range (-10, 4, 2):\n",
    "                aux_custo = 2**j\n",
    "                aux_gamma = 2**i\n",
    "\n",
    "                model = svm_train(Y, X, '-c %f -t %d -g %f -q' %(aux_custo, kernel, aux_gamma))\n",
    "                p_labs, p_acc, p_vals = svm_predict(Yval, Xval, model)\n",
    "\n",
    "                if(p_acc[0] > acc):\n",
    "                    acc = p_acc[0]\n",
    "                    custo = aux_custo\n",
    "                    gamma  = aux_gamma\n",
    "    \n",
    "    ##########################################################################\n",
    "\n",
    "    return custo, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimeRelatorio(p_acc, kernel):\n",
    "    print('\\n\\tAccuracy \\tErro quadratico   \\tCoeficiente correlacao   \\tKernel')\n",
    "    print('\\t%1.3f      \\t%1.3f      \\t\\t%1.3f      \\t\\t\\t%d' % (p_acc[0], p_acc[1], p_acc[2], kernel ) )\n",
    "    \n",
    "    print('\\t------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bestC_linear, bestGamma_linear = gridSearch(bsr_matrix(Xtrain), Ytrain, bsr_matrix(Xvalid), Yvalid, 0)\n",
    "print('Melhores parâmetros\\nLinear - C: %1.3f\\n' %(bestC_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestC_polinomial, bestGamma_polinomial = gridSearch(bsr_matrix(Xtrain), Ytrain, bsr_matrix(Xvalid), Yvalid, 1)\n",
    "print('Melhores parâmetros\\nPolinomial - C: %1.3f, gamma=%1.3f' %(bestC_polinomial,bestGamma_polinomial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestC_radial, bestGamma_radial = gridSearch(bsr_matrix(Xtrain), Ytrain, bsr_matrix(Xvalid), Yvalid, 2)\n",
    "print('Melhores parâmetros\\nRadial - C: %1.3f, gamma=%1.3f' %(bestC_radial,bestGamma_radial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classificador - Kernel radial ### \n",
    "# treina o classificador com o melhor custo e o melhor gamma encontrados \n",
    "# Treinamento e clasificacao com valores de kernel:\n",
    "\n",
    "# 0 -- linear: u\\'\\*v\n",
    "# 1 -- polynomial: (gamma\\*u\\'\\*v + coef0)^degree\n",
    "# 2 -- radial basis function: exp(-gamma\\*|u-v|^2)\n",
    "\n",
    "print('\\n-----------\\nSVM Classifier: \\n-----------\\n')\n",
    "\n",
    "# Kernel linear:\n",
    "model = svm_train(Ytrain, bsr_matrix(Xtrain), '-c %f -t %d' %(bestC_linear, 0))\n",
    "p_labs, p_acc, p_vals = svm_predict(Yvalid, bsr_matrix(Xvalid), model)\n",
    "imprimeRelatorio(p_acc, 0)\n",
    "\n",
    "\n",
    "# Kernel polinomial:\n",
    "model = svm_train(Ytrain, bsr_matrix(Xtrain), '-q -c %f -t %d -g %f' %(bestC_polinomial, 1, bestGamma_polinomial))\n",
    "p_labs, p_acc, p_vals = svm_predict(Yvalid, bsr_matrix(Xvalid), model)\n",
    "imprimeRelatorio(p_acc, 1)\n",
    "\n",
    "# Kernel raidal:\n",
    "model = svm_train(Ytrain, bsr_matrix(Xtrain), '-q -c %f -t %d -g %f' %(bestC_radial, 2, bestGamma_radial))\n",
    "p_labs, p_acc, p_vals = svm_predict(Yvalid, bsr_matrix(Xvalid), model)\n",
    "imprimeRelatorio(p_acc, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curva_aprendizado_linear(Xtrain, Ytrain, Xvalid, Yvalid, Cost):\n",
    "    \"\"\"\n",
    "    Funcao usada gerar a curva de aprendizado.\n",
    "  \n",
    "    Parametros\n",
    "    ----------\n",
    "  \n",
    "    X : matriz com os dados de treinamento\n",
    "  \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "  \n",
    "    Xval : matriz com os dados de validação\n",
    "  \n",
    "    Yval : vetor com as classes dos dados de validação\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # inicializa as listas que guardarao a performance no treinamento e na validacao\n",
    "    perf_train = []\n",
    "    perf_val = []\n",
    "\n",
    "    # inicializa o parametro de regularizacao da regressao logistica\n",
    "    lambda_reg = 1\n",
    "        \n",
    "    # Configura o numero de interacaoes da regressao logistica\n",
    "    iteracoes = 500\n",
    "        \n",
    "    # Kernel radial\n",
    "    kernel = 0\n",
    "    \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    #  Instrucoes: Complete o codigo para gerar o gráfico da curva de aprendizado.\n",
    "    #           Comece o treinamento com as primeiras 10 amostras da base de dados de \n",
    "    #           treinamento e calcule a acuracia do classificador tanto nos dados de\n",
    "    #           treinamento já apresentados, quando na base de validacao. \n",
    "    #           Depois disso, adicione mais um dado para treinamento e calcule novamente \n",
    "    #           o desempenho. Continue adicionando um dado por vez ate todos os dados de \n",
    "    #           treinamento serem usados. Nas listas perf_train e perf_val, guarde a acuracia \n",
    "    #           obtida nos dados de treinamento e na base de validacao a cada nova adicao de \n",
    "    #           dados para treinamento.\n",
    "    for idx, i in enumerate(np.arange(9, len(Xtrain) - 1)):\n",
    "        model = svm_train(Ytrain[:i], bsr_matrix(Xtrain[:i, :]), '-c %f -t %d' %(Cost, kernel))\n",
    "        \n",
    "        # Teste\n",
    "        p_labs, p_acc, p_vals = svm_predict(Ytrain[:i], bsr_matrix(Xtrain[:i, :]), model)\n",
    "        perf_train.append(p_acc[0])\n",
    "        \n",
    "        # Validação\n",
    "        p_labs, p_acc, p_vals = svm_predict(Yvalid, bsr_matrix(Xvalid), model)\n",
    "        perf_val.append(p_acc[0])\n",
    "    \n",
    "    ##################################################################################\n",
    "       \n",
    "    # Define o tamanho da figura \n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    # Plota os dados\n",
    "    plt.plot(perf_train, color='blue', linestyle='-', linewidth=1.5, label='Treino') \n",
    "    plt.plot(perf_val, color='red', linestyle='-', linewidth=1.5, label='Validação')\n",
    "\n",
    "    # Define os nomes do eixo x e do eixo y\n",
    "    plt.xlabel(r'# Qtd. de dados de treinamento',fontsize='x-large') \n",
    "    plt.ylabel(r'Acuracia',fontsize='x-large') \n",
    "\n",
    "    # Define o título do gráfico\n",
    "    plt.title(r'Curva de aprendizado', fontsize='x-large')\n",
    "\n",
    "    # Acrescenta um grid no gráfico\n",
    "    plt.grid(axis='both')\n",
    "\n",
    "    # Plota a legenda\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "curva_aprendizado_linear(Xtrain, Ytrain, Xvalid, Yvalid, bestC_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def curva_aprendizado(Xtrain, Ytrain, Xvalid, Yvalid, Cost, Gamma, kernel):\n",
    "    \"\"\"\n",
    "    Funcao usada gerar a curva de aprendizado.\n",
    "  \n",
    "    Parametros\n",
    "    ----------\n",
    "  \n",
    "    X : matriz com os dados de treinamento\n",
    "  \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "  \n",
    "    Xval : matriz com os dados de validação\n",
    "  \n",
    "    Yval : vetor com as classes dos dados de validação\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # inicializa as listas que guardarao a performance no treinamento e na validacao\n",
    "    perf_train = []\n",
    "    perf_val = []\n",
    "\n",
    "    # inicializa o parametro de regularizacao da regressao logistica\n",
    "    lambda_reg = 1\n",
    "        \n",
    "    # Configura o numero de interacaoes da regressao logistica\n",
    "    iteracoes = 500\n",
    "    \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    #  Instrucoes: Complete o codigo para gerar o gráfico da curva de aprendizado.\n",
    "    #           Comece o treinamento com as primeiras 10 amostras da base de dados de \n",
    "    #           treinamento e calcule a acuracia do classificador tanto nos dados de\n",
    "    #           treinamento já apresentados, quando na base de validacao. \n",
    "    #           Depois disso, adicione mais um dado para treinamento e calcule novamente \n",
    "    #           o desempenho. Continue adicionando um dado por vez ate todos os dados de \n",
    "    #           treinamento serem usados. Nas listas perf_train e perf_val, guarde a acuracia \n",
    "    #           obtida nos dados de treinamento e na base de validacao a cada nova adicao de \n",
    "    #           dados para treinamento.\n",
    "    for idx, i in enumerate(np.arange(9, len(Xtrain) - 1)):\n",
    "        model = svm_train(Ytrain[:i], bsr_matrix(Xtrain[:i, :]), '-q -c %f -t %d -g %f' %(Cost, kernel, Gamma))\n",
    "        \n",
    "        # Teste\n",
    "        p_labs, p_acc, p_vals = svm_predict(Ytrain[:i], bsr_matrix(Xtrain[:i, :]), model)\n",
    "        perf_train.append(p_acc[0])\n",
    "        \n",
    "        # Validação\n",
    "        p_labs, p_acc, p_vals = svm_predict(Yvalid, bsr_matrix(Xvalid), model)\n",
    "        perf_val.append(p_acc[0])\n",
    "    \n",
    "    ##################################################################################\n",
    "       \n",
    "    # Define o tamanho da figura \n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    # Plota os dados\n",
    "    plt.plot(perf_train, color='blue', linestyle='-', linewidth=1.5, label='Treino') \n",
    "    plt.plot(perf_val, color='red', linestyle='-', linewidth=1.5, label='Validação')\n",
    "\n",
    "    # Define os nomes do eixo x e do eixo y\n",
    "    plt.xlabel(r'# Qtd. de dados de treinamento',fontsize='x-large') \n",
    "    plt.ylabel(r'Acuracia',fontsize='x-large') \n",
    "\n",
    "    # Define o título do gráfico\n",
    "    plt.title(r'Curva de aprendizado', fontsize='x-large')\n",
    "\n",
    "    # Acrescenta um grid no gráfico\n",
    "    plt.grid(axis='both')\n",
    "\n",
    "    # Plota a legenda\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "curva_aprendizado(Xtrain, Ytrain, Xvalid, Yvalid, bestC_polinomial, bestGamma_polinomial, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizado(Xtrain, Ytrain, Xvalid, Yvalid, bestC_radial, bestGamma_radial, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "Xk, Yk = Xfeatures[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "nFolds = 10\n",
    "classes = [0,1]\n",
    "iteracoes=1000\n",
    "folds = util.stratified_kfolds(Yk, nFolds, classes) \n",
    "\n",
    "k=1\n",
    "resultados=[]\n",
    "for train_index, test_index in folds:\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "        \n",
    "    totalFold = len(train_index)+len(test_index)\n",
    "\n",
    "    X_train, X_test = Xk[train_index, :], Xk[test_index, :];\n",
    "    Y_train, Y_test = Yk[train_index], Yk[test_index];\n",
    "    \n",
    "    # separa os dados de treinamento em treinamento e validacao\n",
    "    pTrain = 0.8\n",
    "    train_index_v, val_index = util.stratified_holdOut(Y_train, pTrain)\n",
    "    \n",
    "    #bestC_linear, bestGamma_linear = gridSearch(Xtrain, Ytrain, Xvalid, Yvalid, 0)\n",
    "\n",
    "    model = svm_train(Ytrain, bsr_matrix(Xtrain), '-c %f -t %d' %(bestC_linear, 0))\n",
    "    \n",
    "    Y_pred, p_acc, p_vals = svm_predict(Y_test, bsr_matrix(X_test), model)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = util.get_confusionMatrix(Y_test, np.array(Y_pred).astype(int), classes)\n",
    "\n",
    "    # Gera o relatório de desempenho\n",
    "    #print('\\n\\n\\n\\t'+\"=\"*50+'\\n\\tMelhor parametro de regularizacao: %1.6f' %bestRegularization)\n",
    "    print('\\n\\tResultado no fold atual usando o melhor parametro encontrado:')\n",
    "    auxResults = util.relatorioDesempenho(cm, classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults ) \n",
    "        \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nResultado final da classificação:')\n",
    "util.mediaFolds( resultados, classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "Xk, Yk = Xfeatures[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "nFolds = 10\n",
    "classes = [0,1]\n",
    "iteracoes=1000\n",
    "folds = util.stratified_kfolds(Yk, nFolds, classes) \n",
    "\n",
    "k=1\n",
    "resultados=[]\n",
    "for train_index, test_index in folds:\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "        \n",
    "    totalFold = len(train_index)+len(test_index)\n",
    "\n",
    "    X_train, X_test = Xk[train_index, :], Xk[test_index, :];\n",
    "    Y_train, Y_test = Yk[train_index], Yk[test_index];\n",
    "    \n",
    "    # separa os dados de treinamento em treinamento e validacao\n",
    "    pTrain = 0.8\n",
    "    train_index_v, val_index = util.stratified_holdOut(Y_train, pTrain)\n",
    "    \n",
    "    #bestC_polinomial, bestGamma_polinomial = gridSearch(Xtrain, Ytrain, Xvalid, Yvalid, 1)\n",
    "\n",
    "    model = svm_train(Ytrain, bsr_matrix(Xtrain), '-q -c %f -t %d -g %f' %(bestC_polinomial, 1, bestGamma_polinomial))\n",
    "    \n",
    "    Y_pred, p_acc, p_vals = svm_predict(Y_test, bsr_matrix(X_test), model)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = util.get_confusionMatrix(Y_test, np.array(Y_pred).astype(int), classes)\n",
    "\n",
    "    # Gera o relatório de desempenho\n",
    "    #print('\\n\\n\\n\\t'+\"=\"*50+'\\n\\tMelhor parametro de regularizacao: %1.6f' %bestRegularization)\n",
    "    print('\\n\\tResultado no fold atual usando o melhor parametro encontrado:')\n",
    "    auxResults = util.relatorioDesempenho(cm, classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults ) \n",
    "        \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nResultado final da classificação:')\n",
    "util.mediaFolds( resultados, classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "Xk, Yk = Xfeatures[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "nFolds = 10\n",
    "classes = [0,1]\n",
    "iteracoes=1000\n",
    "folds = util.stratified_kfolds(Yk, nFolds, classes) \n",
    "\n",
    "k=1\n",
    "resultados=[]\n",
    "for train_index, test_index in folds:\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "        \n",
    "    totalFold = len(train_index)+len(test_index)\n",
    "\n",
    "    X_train, X_test = Xk[train_index, :], Xk[test_index, :];\n",
    "    Y_train, Y_test = Yk[train_index], Yk[test_index];\n",
    "    \n",
    "    # separa os dados de treinamento em treinamento e validacao\n",
    "    pTrain = 0.8\n",
    "    train_index_v, val_index = util.stratified_holdOut(Y_train, pTrain)\n",
    "    \n",
    "    #bestC_polinomial, bestGamma_polinomial = gridSearch(Xtrain, Ytrain, Xvalid, Yvalid, 1)\n",
    "\n",
    "    model = svm_train(Ytrain, bsr_matrix(Xtrain), '-q -c %f -t %d -g %f' %(bestC_radial, 2, bestGamma_radial))\n",
    "    \n",
    "    Y_pred, p_acc, p_vals = svm_predict(Y_test, bsr_matrix(X_test), model)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = util.get_confusionMatrix(Y_test, np.array(Y_pred).astype(int), classes)\n",
    "\n",
    "    # Gera o relatório de desempenho\n",
    "    #print('\\n\\n\\n\\t'+\"=\"*50+'\\n\\tMelhor parametro de regularizacao: %1.6f' %bestRegularization)\n",
    "    print('\\n\\tResultado no fold atual usando o melhor parametro encontrado:')\n",
    "    auxResults = util.relatorioDesempenho(cm, classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults ) \n",
    "        \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nResultado final da classificação:')\n",
    "util.mediaFolds( resultados, classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
