{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lol' 'atleast' 'csgo' 'archeag' 'keep']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np #importa a biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd #importa a biblioteca usada para trabalhar com dataframes\n",
    "import util\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "from numba import jit, njit\n",
    "from scipy.sparse import bsr_matrix\n",
    "from scipy.linalg.blas import sgemm\n",
    "import cProfile\n",
    "import cupy as cp\n",
    "\n",
    "#importa o arquivo e extrai as features\n",
    "Xfeatures, Y = util.extract_features('datasets/ARCHEAGE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando parametros salvos da rede neural...\n",
      "\n",
      "Pesos carregados com sucesso!\n",
      "(500, 2244)\n",
      "(2, 501)\n",
      "(1123002,)\n"
     ]
    }
   ],
   "source": [
    "# parametros a serem utilizados neste exercicio\n",
    "input_layer_size  = Xfeatures.shape[1]  # 20x20 dimensao das imagens de entrada\n",
    "hidden_layer_size = 500   # 25 neuronios na camada oculta\n",
    "num_labels = 2          # 10 rotulos, de 1 a 10  \n",
    "                         #  (observe que a classe \"0\" recebe o rotulo 10)\n",
    "    \n",
    "print('\\nCarregando parametros salvos da rede neural...\\n')\n",
    "\n",
    "# carregando os pesos da camada 1\n",
    "Theta1 = np.random.rand(hidden_layer_size, input_layer_size+1)*np.sqrt(1/(input_layer_size+hidden_layer_size))\n",
    "\n",
    "# carregando os pesos da camada 2\n",
    "Theta2 = np.random.rand(num_labels, hidden_layer_size+1)*np.sqrt(1/(hidden_layer_size+num_labels))\n",
    "\n",
    "# concatena os pesos em um único vetor\n",
    "nn_params = np.concatenate([np.ravel(Theta1), np.ravel(Theta2)])\n",
    "\n",
    "print('Pesos carregados com sucesso!')\n",
    "print(Theta1.shape)\n",
    "print(Theta2.shape)\n",
    "print(nn_params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@njit\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcula a função sigmoidal  \n",
    "    \"\"\"\n",
    "\n",
    "    z = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inicializando parametros da rede neural...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inicializaPesosAleatorios(L_in, L_out, randomSeed = None):\n",
    "    '''\n",
    "    Inicializa aleatoriamente os pesos de uma camada usando \n",
    "    L_in (conexoes de entrada) e L_out (conexoes de saida).\n",
    "\n",
    "    W sera definido como uma matriz de dimensoes [L_out, 1 + L_in]\n",
    "    visto que devera armazenar os termos para \"bias\".\n",
    "    \n",
    "    randomSeed: indica a semente para o gerador aleatorio\n",
    "    '''\n",
    "\n",
    "    epsilon_init = 0.12\n",
    "    \n",
    "    # se for fornecida uma semente para o gerador aleatorio\n",
    "    if randomSeed is not None:\n",
    "        W = np.random.RandomState(randomSeed).rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "        \n",
    "    # se nao for fornecida uma semente para o gerador aleatorio\n",
    "    else:\n",
    "        W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "        \n",
    "    return W\n",
    "\n",
    "\n",
    "print('\\nInicializando parametros da rede neural...\\n')\n",
    "    \n",
    "#initial_Theta1 = inicializaPesosAleatorios(input_layer_size, hidden_layer_size, randomSeed = 10)\n",
    "#initial_Theta2 = inicializaPesosAleatorios(hidden_layer_size, num_labels, randomSeed = 20)\n",
    "\n",
    "# junta os pesos iniciais em um unico vetor\n",
    "#initial_rna_params = np.concatenate([np.ravel(initial_Theta1), np.ravel(initial_Theta2)])\n",
    "initial_rna_params = nn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@njit\n",
    "def sigmoidGradient(z):\n",
    "    '''\n",
    "    Retorna o gradiente da funcao sigmoidal para z \n",
    "    \n",
    "    Calcula o gradiente da funcao sigmoidal\n",
    "    para z. A funcao deve funcionar independente se z for matriz ou vetor.\n",
    "    Nestes casos,  o gradiente deve ser calculado para cada elemento.\n",
    "    '''\n",
    "    \n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instrucoes: Calcula o gradiente da funcao sigmoidal para \n",
    "    #           cada valor de z (seja z matriz, escalar ou vetor).\n",
    "    #\n",
    "\n",
    "    g = sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "    ##########################################################################\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Checando a funcao de custo (c/ regularizacao) ... \n",
      "\n",
      "         86 function calls in 0.423 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        4    0.116    0.029    0.116    0.029 <ipython-input-23-a108a933bf09>:2(sigmoid)\n",
      "        1    0.016    0.016    0.095    0.095 <ipython-input-25-2298d1932d21>:2(sigmoidGradient)\n",
      "        1    0.049    0.049    0.408    0.408 <ipython-input-26-e21933449eec>:7(funcaoCusto_backp_reg)\n",
      "        1    0.015    0.015    0.423    0.423 <string>:1(<module>)\n",
      "        4    0.000    0.000    0.002    0.001 _methods.py:31(_sum)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:1427(ravel)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:163(reshape)\n",
      "        4    0.000    0.000    0.002    0.001 fromnumeric.py:1778(sum)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:50(_wrapfunc)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:146(ones)\n",
      "        6    0.000    0.000    0.000    0.000 numeric.py:495(asanyarray)\n",
      "        2    0.000    0.000    0.029    0.015 shape_base.py:182(vstack)\n",
      "        2    0.000    0.000    0.000    0.000 shape_base.py:234(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 shape_base.py:63(atleast_2d)\n",
      "        1    0.000    0.000    0.423    0.423 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        7    0.005    0.001    0.005    0.001 {built-in method numpy.core.multiarray.array}\n",
      "        3    0.035    0.012    0.035    0.012 {built-in method numpy.core.multiarray.concatenate}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.copyto}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.empty}\n",
      "        5    0.184    0.037    0.184    0.037 {built-in method numpy.core.multiarray.matmul}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.zeros}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "        4    0.002    0.001    0.002    0.001 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.generic' objects}\n",
      "\n",
      "\n",
      "Custo com os parametros (carregados do arquivo): 5.819845\n"
     ]
    }
   ],
   "source": [
    "def l2a(Y, num_labels):\n",
    "    n = len(Y)\n",
    "    y = np.zeros((n, num_labels))\n",
    "    y[np.arange(n), Y] = 1\n",
    "    return y\n",
    "\n",
    "def funcaoCusto_backp_reg(nn_params, input_layer_size, hidden_layer_size, num_labels, X, Y, vLambda):\n",
    "    '''\n",
    "    Implementa a funcao de custo para a rede neural com tres camadas\n",
    "    voltada para tarefa de classificacao\n",
    "    \n",
    "    Calcula o custo e gradiente da rede neural. \n",
    "    Os parametros da rede neural sao colocados no vetor nn_params\n",
    "    e precisam ser transformados de volta nas matrizes de peso.\n",
    "    \n",
    "    input_layer_size - tamanho da camada de entrada\n",
    "    hidden_layer_size - tamanho da camada oculta\n",
    "    num_labels - numero de classes possiveis\n",
    "    lambda - parametro de regularizacao\n",
    "    \n",
    "    O vetor grad de retorno contem todas as derivadas parciais\n",
    "    da rede neural.\n",
    "    '''\n",
    "\n",
    "    # Extrai os parametros de nn_params e alimenta as variaveis Theta1 e Theta2.\n",
    "    Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "    Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "    # Qtde de amostras\n",
    "    m = X.shape[0]\n",
    "         \n",
    "    # As variaveis a seguir precisam ser retornadas corretamente\n",
    "    J = 0;\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    \n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instrucoes: Voce deve completar o codigo a partir daqui \n",
    "    #               acompanhando os seguintes passos.\n",
    "    #\n",
    "    # (1): Lembre-se de transformar os rotulos Y em vetores com 10 posicoes,\n",
    "    #         onde tera zero em todas posicoes exceto na posicao do rotulo\n",
    "    #\n",
    "    # (2): Execute a etapa de feedforward e coloque o custo na variavel J.\n",
    "    #\n",
    "    # (3): Implemente o algoritmo de backpropagation para calcular \n",
    "    #      os gradientes e alimentar as variaveis Theta1_grad e Theta2_grad.\n",
    "    #\n",
    "    # (4): Implemente a regularização na função de custo e gradiente.\n",
    "    #\n",
    "    \n",
    "    a1 = np.vstack([np.ones(X.T.shape[1]), X.T])\n",
    "    z2 = np.matmul(Theta1, a1)\n",
    "    a2 = np.vstack([np.ones(z2.shape[1]), sigmoid(z2)])\n",
    "    a2 = np.array(a2)\n",
    "    z3 = np.matmul(Theta2, a2)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    reg = vLambda / (2*m) * (np.sum(Theta1[:,1:] ** 2) + np.sum(Theta2[:,1:] ** 2))\n",
    "    J = 1/m * np.sum(np.sum(-Y * np.log(a3.T) - (1 - Y) * np.log(1 - a3.T))) + reg\n",
    "\n",
    "    d3 = a3 - Y.T\n",
    "    d2 = np.multiply(np.matmul(Theta2[:,1:].T, d3), sigmoidGradient(z2))\n",
    "\n",
    "    Theta1_grad = 1 / m * np.matmul(d2, a1.T)\n",
    "    Theta2_grad = 1 / m * np.matmul(d3, a2.T)\n",
    "\n",
    "    reg1 = (vLambda / m) * Theta1\n",
    "    reg1[:,0] = 0\n",
    "    reg2 = (vLambda / m) * Theta2\n",
    "    reg2[:,0] = 0\n",
    "    \n",
    "    Theta1_grad = Theta1_grad + reg1\n",
    "    Theta2_grad = Theta2_grad + reg2\n",
    "\n",
    "    ##########################################################################\n",
    "\n",
    "    # Junta os gradientes\n",
    "    grad = np.concatenate([np.ravel(Theta1_grad), np.ravel(Theta2_grad)])\n",
    "\n",
    "    return J, grad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parametro de regularizacao dos pesos.\n",
    "vLambda = 3;\n",
    "\n",
    "print('\\n\\nChecando a funcao de custo (c/ regularizacao) ... \\n')\n",
    "\n",
    "Yl = l2a(Y, num_labels)\n",
    "\n",
    "cProfile.run('funcaoCusto_backp_reg(nn_params, input_layer_size, hidden_layer_size, num_labels, Xfeatures, Yl, vLambda)')\n",
    "J, grad = funcaoCusto_backp_reg(nn_params, input_layer_size, hidden_layer_size, num_labels, Xfeatures, Yl, vLambda)\n",
    "\n",
    "print('Custo com os parametros (carregados do arquivo): %1.6f' %J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando a rede neural.......\n",
      ".......(Aguarde, pois esse processo por ser um pouco demorado.)\n",
      "\n",
      "     fun: 1.2087078914218636\n",
      "     jac: array([ 1.43074736e-07,  1.34008481e-08, -1.07373237e-09, ...,\n",
      "        5.52353467e-06,  1.91853474e-06,  9.42686142e-06])\n",
      " message: 'Max. number of function evaluations reached'\n",
      "    nfev: 500\n",
      "     nit: 49\n",
      "  status: 3\n",
      " success: False\n",
      "       x: array([-4.31080562e-02,  1.34008481e-07, -1.07373237e-08, ...,\n",
      "       -7.00591017e-02,  7.23071839e-02, -1.88920047e-02])\n"
     ]
    }
   ],
   "source": [
    "print('\\nTreinando a rede neural.......')\n",
    "print('.......(Aguarde, pois esse processo por ser um pouco demorado.)\\n')\n",
    "\n",
    "# Apos ter completado toda a tarefa, mude o parametro MaxIter para\n",
    "# um valor maior e verifique como isso afeta o treinamento.\n",
    "MaxIter = 500\n",
    "\n",
    "# Voce tambem pode testar valores diferentes para lambda.\n",
    "vLambda = 1\n",
    "\n",
    "# Minimiza a funcao de custo\n",
    "result = scipy.optimize.minimize(fun=funcaoCusto_backp_reg, x0=initial_rna_params, args=(input_layer_size, hidden_layer_size, num_labels, Xfeatures, Yl, vLambda),  \n",
    "                method='TNC', jac=True, options={'maxiter': MaxIter})\n",
    "\n",
    "# Coleta os pesos retornados pela função de minimização\n",
    "nn_params = result.x\n",
    "\n",
    "# Obtem Theta1 e Theta2 back a partir de rna_params\n",
    "Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-a167cad4ba3a>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"predicao\" failed type inference due to: \u001b[1mUntyped global name 'sigmoid':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-27-a167cad4ba3a>\", line 18:\u001b[0m\n",
      "\u001b[1mdef predicao(Theta1, Theta2, X):\n",
      "    <source elided>\n",
      "    a1 = np.hstack( [np.ones([m,1]),X] )\n",
      "\u001b[1m    h1 = sigmoid( np.dot(a1,Theta1.T) )\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n",
      "[1 0 0 1 0]\n",
      "\n",
      "Acuracia no conjunto de treinamento: 42.142026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\numba\\compiler.py:725: NumbaWarning: \u001b[1mFunction \"predicao\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-27-a167cad4ba3a>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef predicao(Theta1, Theta2, X):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  self.func_ir.loc))\n",
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\numba\\compiler.py:734: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-27-a167cad4ba3a>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef predicao(Theta1, Theta2, X):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def predicao(Theta1, Theta2, X):\n",
    "    '''\n",
    "    Prediz o rotulo de uma amostra apresentada a rede neural\n",
    "    \n",
    "    Prediz o rotulo de X ao utilizar\n",
    "    os pesos treinados na rede neural (Theta1, Theta2)\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[0] # número de amostras\n",
    "    num_labels = Theta2.shape[0]\n",
    "    \n",
    "    p = np.zeros(m)\n",
    "    \n",
    "    a1 = np.zeros((m,m+1))\n",
    "\n",
    "    a1 = np.hstack( [np.ones([m,1]),X] )\n",
    "    h1 = sigmoid( np.dot(a1,Theta1.T) )\n",
    "    \n",
    "    a2 = np.hstack( [np.ones([m,1]),h1] ) \n",
    "    h2 = sigmoid( cp.dot(a2,Theta2.T) )\n",
    "    \n",
    "    p = np.argmax(h2,axis=1)\n",
    "    #p = p+1\n",
    "    \n",
    "    return p\n",
    "    \n",
    "\n",
    "pred = predicao(Theta1, Theta2, Xfeatures)\n",
    "print(pred[:5])\n",
    "print(Y[:5])\n",
    "\n",
    "print('\\nAcuracia no conjunto de treinamento: %f\\n'%( np.mean( pred == Y ) * 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Theta1).to_csv('pesos_Theta1.csv', index=False)\n",
    "pd.DataFrame(Theta2).to_csv('pesos_Theta2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de dados de validação: 275\n"
     ]
    }
   ],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "Xk, Yk = Xfeatures[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "# define a porcentagem de dados que irao compor o conjunto de treinamento\n",
    "pTrain = 0.8\n",
    "\n",
    "# obtem os indices dos dados da particao de treinamento e da particao de teste\n",
    "train_index, test_index = util.stratified_holdOut(Yk, pTrain)\n",
    "\n",
    "X_train, X_test = Xk[train_index, :], Xk[test_index, :];\n",
    "Y_train, Y_test = Yk[train_index], Yk[test_index];\n",
    "\n",
    "train_index, val_index = util.stratified_holdOut(Y_train, pTrain)\n",
    "\n",
    "X_train_v, X_val = X_train[train_index, :], X_train[val_index, :]\n",
    "Y_train_v, Y_val = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "print('Numero de dados de validação: %d' %(X_val.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\Documents\\UFSCar\\BCC7\\AM\\AM-2019-1\\util.py:271: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fmedida = 2 * (precisao * revocacao) / (precisao + revocacao)\n",
      "C:\\Users\\Gabriel\\Documents\\UFSCar\\BCC7\\AM\\AM-2019-1\\util.py:275: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fmedida_macroAverage = 2 * (precisao_macroAverage * revocacao_macroAverage) / (precisao_macroAverage + revocacao_macroAverage)\n",
      "C:\\Users\\Gabriel\\Documents\\UFSCar\\BCC7\\AM\\AM-2019-1\\util.py:279: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fmedida_microAverage = 2 * (precisao_microAverage * revocacao_microAverage) / (precisao_microAverage + revocacao_microAverage)\n"
     ]
    }
   ],
   "source": [
    "classes = [0,1]\n",
    "def gridSearch(X, Y, Xval, Yval):\n",
    "    \"\"\"\n",
    "    Retorna o melhor valor para os parametros lamba da regularizacao da Regressao Logistica.\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    X : matriz com os dados de treinamento\n",
    "    \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "    \n",
    "    Xval : matriz com os dados de validacao\n",
    "    \n",
    "    Yval : vetor com as classes dos dados de validacao\n",
    "    \n",
    "    Retorno\n",
    "    -------\n",
    "    bestReg: o melhor valor para o parametro de regularizacao\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # inicializa a variável que deverá ser retornada pela função\n",
    "    bestReg = -100\n",
    "    \n",
    "    # Configura o numero de interacaoes da regressao logistica\n",
    "    iteracoes = 500\n",
    "    \n",
    "    # valores que deverao ser testados para o parametro de regularizacao \n",
    "    reg = [0,0.5,1,10,50,100];\n",
    "        \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    # Instrucoes: Complete esta função para retornar os melhores valores do parametro\n",
    "    #             de regularizacao da regressao Logistica. \n",
    "    #\n",
    "    #             Você pode calcular o desempenho do classificador atraves da funcao\n",
    "    #             relatorioDesempenho() criada anteriormente. Use a acuracia para decidir\n",
    "    #             o melhor parametro.            \n",
    "    #\n",
    "    \n",
    "    perf = []\n",
    "\n",
    "    '''\n",
    "    def regmax(i):\n",
    "        result = scipy.optimize.minimize(fun=funcaoCusto_backp_reg, x0=initial_rna_params, args=(input_layer_size, hidden_layer_size, num_labels, X, Y, i),  \n",
    "                method='L-BFGS-B', jac=True, options={'maxiter': MaxIter})\n",
    "\n",
    "        # Coleta os pesos retornados pela função de minimização\n",
    "        nn_params = result.x\n",
    "\n",
    "        # Obtem Theta1 e Theta2 back a partir de rna_params\n",
    "        Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "        Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "        # classifica os dados de teste\n",
    "        Y_pred = predicao(Theta1, Theta2, X_val)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = util.get_confusionMatrix(Y_val, Y_pred, classes)\n",
    "        results = util.relatorioDesempenho(cm, [0,1])\n",
    "        return results['acuracia']\n",
    "    \n",
    "    vregmax = np.vectorize(regmax, otypes=['float'])\n",
    "    perf = vregmax(reg)\n",
    "    '''\n",
    "\n",
    "    for i in reg:\n",
    "        result = scipy.optimize.minimize(fun=funcaoCusto_backp_reg, x0=initial_rna_params, args=(input_layer_size, hidden_layer_size, num_labels, X, Y, i),  \n",
    "                method='L-BFGS-B', jac=True, options={'maxiter': MaxIter})\n",
    "\n",
    "        # Coleta os pesos retornados pela função de minimização\n",
    "        nn_params = result.x\n",
    "\n",
    "        # Obtem Theta1 e Theta2 back a partir de rna_params\n",
    "        Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "        Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "        # classifica os dados de teste\n",
    "        Y_pred = predicao(Theta1, Theta2, X_val)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = util.get_confusionMatrix(Y_val, Y_pred, classes)\n",
    "        results = util.relatorioDesempenho(cm, [0,1])\n",
    "        return results['acuracia']\n",
    "        perf.append(results['acuracia'])\n",
    "        \n",
    "    bestReg = reg[np.argmax(perf)]\n",
    "\n",
    "    ################################################################################## \n",
    "\n",
    "    return bestReg\n",
    "\n",
    "\n",
    "%timeit\n",
    "bestLambda = gridSearch(X_train_v, l2a(Y_train_v, num_labels), X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23f5f966e48>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def curva_aprendizado(X, Y, Xval, Yval, Yl):\n",
    "    \"\"\"\n",
    "    Funcao usada gerar a curva de aprendizado.\n",
    "  \n",
    "    Parametros\n",
    "    ----------\n",
    "  \n",
    "    X : matriz com os dados de treinamento\n",
    "  \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "  \n",
    "    Xval : matriz com os dados de validação\n",
    "  \n",
    "    Yval : vetor com as classes dos dados de validação\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # inicializa as listas que guardarao a performance no treinamento e na validacao\n",
    "    perf_train = []\n",
    "    perf_val = []\n",
    "\n",
    "    # inicializa o parametro de regularizacao da regressao logistica\n",
    "    lambda_reg = 1\n",
    "        \n",
    "    # Configura o numero de interacaoes da regressao logistica\n",
    "    iteracoes = 500\n",
    "        \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    #  Instrucoes: Complete o codigo para gerar o gráfico da curva de aprendizado.\n",
    "    #           Comece o treinamento com as primeiras 10 amostras da base de dados de \n",
    "    #           treinamento e calcule a acuracia do classificador tanto nos dados de\n",
    "    #           treinamento já apresentados, quando na base de validacao. \n",
    "    #           Depois disso, adicione mais um dado para treinamento e calcule novamente \n",
    "    #           o desempenho. Continue adicionando um dado por vez ate todos os dados de \n",
    "    #           treinamento serem usados. Nas listas perf_train e perf_val, guarde a acuracia \n",
    "    #           obtida nos dados de treinamento e na base de validacao a cada nova adicao de \n",
    "    #           dados para treinamento.\n",
    "    \n",
    "    for i in np.arange(9, len(X) - 1):\n",
    "        print(i)\n",
    "        # Apos ter completado toda a tarefa, mude o parametro MaxIter para\n",
    "        # um valor maior e verifique como isso afeta o treinamento.\n",
    "        MaxIter = 500\n",
    "\n",
    "        # Voce tambem pode testar valores diferentes para lambda.\n",
    "        vLambda = bestLambda\n",
    "\n",
    "        # Minimiza a funcao de custo\n",
    "        result = scipy.optimize.minimize(fun=funcaoCusto_backp_reg, x0=initial_rna_params, args=(input_layer_size, hidden_layer_size, num_labels, X[:i], Yl[:i], vLambda),  \n",
    "                method='L-BFGS-B', jac=True, options={'maxiter': MaxIter})\n",
    "\n",
    "        # Coleta os pesos retornados pela função de minimização\n",
    "        nn_params = result.x\n",
    "\n",
    "        # Obtem Theta1 e Theta2 back a partir de rna_params\n",
    "        Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "        Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "        \n",
    "        Theta1 = cp.array(Theta1)\n",
    "        Theta2 = cp.array(Theta2)\n",
    "\n",
    "        \n",
    "        # Teste\n",
    "        p = predicao(Theta1, Theta2, X[:i])\n",
    "        cm = util.get_confusionMatrix(cp.asnumpy(Y[:i]), p, [0,1])\n",
    "        results = util.relatorioDesempenho(cm, [0,1])\n",
    "        perf_train.append(results['acuracia'])\n",
    "        # Validação\n",
    "        p = predicao(Theta1, Theta2, Xval[:i])\n",
    "        cm = util.get_confusionMatrix(cp.asnumpy(Yval[:i]), p, [0,1])\n",
    "        results = util.relatorioDesempenho(cm, [0,1])\n",
    "        perf_val.append(results['acuracia'])\n",
    "\n",
    "    ##################################################################################\n",
    "       \n",
    "    # Define o tamanho da figura \n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    # Plota os dados\n",
    "    plt.plot(perf_train, color='blue', linestyle='-', linewidth=1.5, label='Treino') \n",
    "    plt.plot(perf_val, color='red', linestyle='-', linewidth=1.5, label='Validação')\n",
    "\n",
    "    # Define os nomes do eixo x e do eixo y\n",
    "    plt.xlabel(r'# Qtd. de dados de treinamento',fontsize='x-large') \n",
    "    plt.ylabel(r'Acuracia',fontsize='x-large') \n",
    "\n",
    "    # Define o título do gráfico\n",
    "    plt.title(r'Curva de aprendizado', fontsize='x-large')\n",
    "\n",
    "    # Acrescenta um grid no gráfico\n",
    "    plt.grid(axis='both')\n",
    "\n",
    "    # Plota a legenda\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "curva_aprendizado(X_train_v, cp.array(Y_train_v), X_val, Y_val, cp.array(Yl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(bestLambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "1-fold: \n",
      "-----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: RuntimeWarning: divide by zero encountered in log\n",
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tResultado no fold atual usando o melhor parametro encontrado:\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.869       0.811      0.839      0\n",
      "\t0.722       0.800      0.759      1\n",
      "\t------------------------------------------------\n",
      "\t0.795       0.806      0.801      Média macro\n",
      "\t0.807       0.807      0.807      Média micro\n",
      "\n",
      "\tAcuracia: 0.807\n",
      "\n",
      "-----------\n",
      "2-fold: \n",
      "-----------\n",
      "\n",
      "\n",
      "\tResultado no fold atual usando o melhor parametro encontrado:\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.848       0.840      0.844      0\n",
      "\t0.778       0.789      0.783      1\n",
      "\t------------------------------------------------\n",
      "\t0.813       0.814      0.814      Média macro\n",
      "\t0.819       0.819      0.819      Média micro\n",
      "\n",
      "\tAcuracia: 0.819\n",
      "\n",
      "-----------\n",
      "3-fold: \n",
      "-----------\n",
      "\n",
      "\n",
      "\tResultado no fold atual usando o melhor parametro encontrado:\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.848       0.832      0.840      0\n",
      "\t0.764       0.786      0.775      1\n",
      "\t------------------------------------------------\n",
      "\t0.806       0.809      0.807      Média macro\n",
      "\t0.813       0.813      0.813      Média micro\n",
      "\n",
      "\tAcuracia: 0.813\n",
      "\n",
      "-----------\n",
      "4-fold: \n",
      "-----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "Xk, Yk = Xfeatures[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "nFolds = 10\n",
    "classes = [0,1]\n",
    "iteracoes=1000\n",
    "folds = util.stratified_kfolds(Yk, nFolds, classes) \n",
    "\n",
    "k=1\n",
    "resultados=[]\n",
    "for train_index, test_index in folds:\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "        \n",
    "    totalFold = len(train_index)+len(test_index)\n",
    "\n",
    "    X_train, X_test = Xk[train_index, :], Xk[test_index, :];\n",
    "    Y_train, Y_test = Yk[train_index], Yk[test_index];\n",
    "    \n",
    "    # separa os dados de treinamento em treinamento e validacao\n",
    "    pTrain = 0.8\n",
    "    train_index_v, val_index = util.stratified_holdOut(Y_train, pTrain)\n",
    "\n",
    "    # Apos ter completado toda a tarefa, mude o parametro MaxIter para\n",
    "    # um valor maior e verifique como isso afeta o treinamento.\n",
    "    MaxIter = 500\n",
    "\n",
    "    # Voce tambem pode testar valores diferentes para lambda.\n",
    "    vLambda = 1\n",
    "    \n",
    "    # chama a função que faz a busca em grade\n",
    "    #vLambda = gridSearch(X_train_v, Y_train_v, X_val, Y_val)\n",
    "    vLambda = bestLambda\n",
    "\n",
    "    # Minimiza a funcao de custo\n",
    "    result = scipy.optimize.minimize(fun=funcaoCusto_backp_reg, x0=initial_rna_params, args=(input_layer_size, hidden_layer_size, num_labels, Xfeatures, Yl, vLambda),  \n",
    "                method='TNC', jac=True, options={'maxiter': MaxIter})\n",
    "\n",
    "    # Coleta os pesos retornados pela função de minimização\n",
    "    nn_params = result.x\n",
    "\n",
    "    # Obtem Theta1 e Theta2 back a partir de rna_params\n",
    "    Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "    Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "    # classifica os dados de teste\n",
    "    Y_pred = predicao(Theta1, Theta2, X_test)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = util.get_confusionMatrix(Y_test, Y_pred, classes)\n",
    "\n",
    "    # Gera o relatório de desempenho\n",
    "    #print('\\n\\n\\n\\t'+\"=\"*50+'\\n\\tMelhor parametro de regularizacao: %1.6f' %bestRegularization)\n",
    "    print('\\n\\tResultado no fold atual usando o melhor parametro encontrado:')\n",
    "    auxResults = util.relatorioDesempenho(cm, classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults ) \n",
    "        \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nResultado final da classificação:')\n",
    "util.mediaFolds( resultados, classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
