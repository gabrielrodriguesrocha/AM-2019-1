{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np #importa a biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd #importa a biblioteca usada para trabalhar com dataframes\n",
    "import util\n",
    "\n",
    "#importa o arquivo e extrai as features\n",
    "Xfeatures, Y = util.extract_features('datasets/HOBBIT.csv', rep='ngrams',n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(X):\n",
    "    \"\"\"\n",
    "    Normaliza os atributos em X\n",
    "    \n",
    "    Esta função retorna uma versao normalizada de X onde o valor da\n",
    "    média de cada atributo é igual a 0 e desvio padrao é igual a 1. Trata-se de\n",
    "    um importante passo de pré-processamento quando trabalha-se com \n",
    "    métodos de aprendizado de máquina.\n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = X.shape # m = qtde de objetos e n = qtde de atributos por objeto\n",
    "    \n",
    "    # Inicializa as variaves de saída\n",
    "    X_norm = np.zeros( (m,n) ) #inicializa X_norm (base normalizada)\n",
    "    mu = 0 # inicializa a média\n",
    "    sigma = 1 # inicializa o desvio padrão\n",
    "    \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instruções: Calcule a média de cada atributo de X e armazene em mu. Note\n",
    "    #          que se X for uma matriz (m x n), então mu terá que ser um\n",
    "    #          vetor (1 x n), no qual cada coluna de mu deverá conter o \n",
    "    #          valor da média de cada um dos n atributos. O mesmo deverá ser\n",
    "    #          feito para o desvio padrão, que deverá ser armazenado em\n",
    "    #          sigma. \n",
    "    #          Sugestão: use as funções mean e std da biblioteca numpy para  \n",
    "    #                    calcular a média e o desvio padrão, respectivamente.\n",
    "    #                    Se você for usar a função do Numpy para calcular o \n",
    "    #                    desvio padrão, não se esqueça de usar o parâmetro ddof=1 \n",
    "    #                    para fazer a correção de Bessel         \n",
    "    #          Uma vez encontrados os valores de mu e de sigma, calcule o\n",
    "    #          valor do atributo X normalizado. Para isso, para cada amostra\n",
    "    #          x_i de X será necessário calcular (x_i - mu)/sigma e\n",
    "    #          armazenar em X_norm (base de dados normalizada).\n",
    "    \n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0, ddof=1)\n",
    "    X_norm = (X - mu) / sigma\n",
    "    ##########################################################################\n",
    "    \n",
    "    return X_norm, mu, sigma\n",
    "\n",
    "Xfeatures, mu, sigma = normalizar(Xfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia(x, X):\n",
    "    \"\"\"\n",
    "    DISTANCIA calcula a distância entre a amostra x e todos as amostras da \n",
    "    base X.\n",
    "    D = DISTANCIA (x, X) retorna um vetor de distâncias entre a amostra x \n",
    "    e todas as amostras da base X. Cada posição Di = dist(x, Xi).\n",
    " \n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializa a variável de retorno e algumas variáveis úteis\n",
    "    \n",
    "    m = X.shape[0] # Quantidade de objetos em X\n",
    "    D = np.zeros(m) # Inicializa a matriz de distâncias D\n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instruções: Teoricamente, você poderia usar qualquer função de \n",
    "    #          distancia. Porém, para este exercicio, é necessário usar a \n",
    "    #          distância Euclidiana (funcao norm).\n",
    "    # \n",
    "    # Obs: use um loop-for para calcular a distância entre o objeto x e cada\n",
    "    #   amostra Xi de X. O vetor D deverá ter o mesmo número de linhas de X.\n",
    "    # \n",
    "    D = 1 - np.matmul(x, X.T)/(np.linalg.norm(x) * np.linalg.norm(X))\n",
    "    ##########################################################################\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(x, X, Y, K):\n",
    "    \"\"\"\n",
    "    KNN método dos K-vizinhos mais proximos para predizer a classe de um novo\n",
    "    dado.\n",
    "\n",
    "    KNN (x, X, Y, K) retorna o rótulo y da amostra x e os índices\n",
    "        [ind_viz] dos K-vizinhos mais próximos de x em X.\n",
    " \n",
    "        Parâmetros de entrada:\n",
    "        -> x (1 x n): amostra a ser classificada\n",
    "        -> X (m x n): base de dados de treinamento\n",
    "        -> Y (m x 1): conjunto de rótulos de cada amostra de X\n",
    "        -> K (1 x 1): quantidade de vizinhos mais próximos\n",
    " \n",
    "        Parâmetros de saída:\n",
    "        -> y (1 x 1): predição (0 ou 1) do rótulo da amostra x\n",
    "        -> ind_viz (K x 1): índice das K amostras mais próximas de x\n",
    "                            encontradas em X (da mais próxima para a menos\n",
    "                            próxima)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializa a variável de retorno e algumas variáveis uteis\n",
    "    y = 0 # Inicializa rótulo como sendo da classe negativa\n",
    "    ind_viz = np.ones(K, dtype=int) # Inicializa índices (linhas) em X das K amostras mais \n",
    "                         # próximas de x.\n",
    "        \n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instruções: Implemente o método dos K-vizinhos mais próximos. Primeiro, \n",
    "    #         é preciso calcular a distância entre x e cada amostra de X. \n",
    "    #         Depois, encontre os K-vizinhos mais próximos e use voto\n",
    "    #         majoritário para definir o rótulo de x. \n",
    "    #\n",
    "    # Obs: primeiro é necessario implementar a função de distância Euclidiana\n",
    "    #     (distancia).\n",
    "    #\n",
    "\n",
    "    # Calcula a distância entre a amostra de teste x e cada amostra de X. Você\n",
    "    # deverá completar essa função.\n",
    "    \n",
    "    pred = np.zeros(len(x))\n",
    "    \n",
    "    for idx, i in enumerate(x):\n",
    "        ind_viz = np.argsort(distancia(i,X))[:K]\n",
    "        if np.count_nonzero(Y[ind_viz]) > len(ind_viz) / 2:\n",
    "            pred[idx] = 1\n",
    "\n",
    "    ##########################################################################\n",
    "    \n",
    "    return pred, ind_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "Xk, Yk = Xfeatures[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "# define a porcentagem de dados que irao compor o conjunto de treinamento\n",
    "pTrain = 0.8 \n",
    "\n",
    "# obtem os indices dos dados da particao de treinamento e da particao de teste\n",
    "train_index, test_index = util.stratified_holdOut(Yk, pTrain)\n",
    "\n",
    "X_train, X_test = Xk[train_index, :], Xk[test_index, :];\n",
    "Y_train, Y_test = Yk[train_index], Yk[test_index];\n",
    "\n",
    "train_index, val_index = util.stratified_holdOut(Y_train, pTrain)\n",
    "\n",
    "X_train_v, X_val = X_train[train_index, :], X_train[val_index, :]\n",
    "Y_train_v, Y_val = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "print('Numero de dados de validação: %d' %(X_val.shape[0]))\n",
    "\n",
    "K = 1\n",
    "\n",
    "def curva_aprendizado(X, Y, Xval, Yval):\n",
    "    \"\"\"\n",
    "    Funcao usada gerar a curva de aprendizado.\n",
    "  \n",
    "    Parametros\n",
    "    ----------\n",
    "  \n",
    "    X : matriz com os dados de treinamento\n",
    "  \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "  \n",
    "    Xval : matriz com os dados de validação\n",
    "  \n",
    "    Yval : vetor com as classes dos dados de validação\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # inicializa as listas que guardarao a performance no treinamento e na validacao\n",
    "    perf_train = []\n",
    "    perf_val = []\n",
    "\n",
    "    # inicializa o parametro de regularizacao da regressao logistica\n",
    "    lambda_reg = 1\n",
    "        \n",
    "    # Configura o numero de interacaoes da regressao logistica\n",
    "    iteracoes = 500\n",
    "        \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    #  Instrucoes: Complete o codigo para gerar o gráfico da curva de aprendizado.\n",
    "    #           Comece o treinamento com as primeiras 10 amostras da base de dados de \n",
    "    #           treinamento e calcule a acuracia do classificador tanto nos dados de\n",
    "    #           treinamento já apresentados, quando na base de validacao. \n",
    "    #           Depois disso, adicione mais um dado para treinamento e calcule novamente \n",
    "    #           o desempenho. Continue adicionando um dado por vez ate todos os dados de \n",
    "    #           treinamento serem usados. Nas listas perf_train e perf_val, guarde a acuracia \n",
    "    #           obtida nos dados de treinamento e na base de validacao a cada nova adicao de \n",
    "    #           dados para treinamento.\n",
    "    \n",
    "    pVitoria = sum(Y==1)/len(Y) \n",
    "    pDerrota = sum(Y==0)/len(Y)\n",
    "    \n",
    "    ptrain, idx = knn(X, X, Y, K)\n",
    "    pval, idx = knn(Xval, X, Y, K)\n",
    "    for idx, i in enumerate(np.arange(9, len(X) - 1)):\n",
    "        # Teste\n",
    "        cm = util.get_confusionMatrix(Y[:i], ptrain[:i], [0,1])\n",
    "        results = util.relatorioDesempenho(cm, [0,1])\n",
    "        perf_train.append(results['acuracia'])\n",
    "        # Validação\n",
    "        cm = util.get_confusionMatrix(Yval[:i], pval[:i], [0,1])\n",
    "        results = util.relatorioDesempenho(cm, [0,1])\n",
    "        perf_val.append(results['acuracia'])\n",
    "    \n",
    "    ##################################################################################\n",
    "       \n",
    "    # Define o tamanho da figura \n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    # Plota os dados\n",
    "    plt.plot(perf_train, color='blue', linestyle='-', linewidth=1.5, label='Treino') \n",
    "    plt.plot(perf_val, color='red', linestyle='-', linewidth=1.5, label='Validação')\n",
    "\n",
    "    # Define os nomes do eixo x e do eixo y\n",
    "    plt.xlabel(r'# Qtd. de dados de treinamento',fontsize='x-large') \n",
    "    plt.ylabel(r'Acuracia',fontsize='x-large') \n",
    "\n",
    "    # Define o título do gráfico\n",
    "    plt.title(r'Curva de aprendizado', fontsize='x-large')\n",
    "\n",
    "    # Acrescenta um grid no gráfico\n",
    "    plt.grid(axis='both')\n",
    "\n",
    "    # Plota a legenda\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "curva_aprendizado(X_train_v, Y_train_v, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(X, Y, Xval, Yval):\n",
    "    \"\"\"\n",
    "    Retorna o melhor valor para os parametros lamba da regularizacao da Regressao Logistica.\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    X : matriz com os dados de treinamento\n",
    "    \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "    \n",
    "    Xval : matriz com os dados de validacao\n",
    "    \n",
    "    Yval : vetor com as classes dos dados de validacao\n",
    "    \n",
    "    Retorno\n",
    "    -------\n",
    "    bestReg: o melhor valor para o parametro de regularizacao\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # inicializa a variável que deverá ser retornada pela função\n",
    "    bestK = -100\n",
    "    \n",
    "    # valores que deverao ser testados para o parametro de regularizacao \n",
    "    K = [1,2,4,8,10,12];\n",
    "        \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    # Instrucoes: Complete esta função para retornar os melhores valores do parametro\n",
    "    #             de regularizacao da regressao Logistica. \n",
    "    #\n",
    "    #             Você pode calcular o desempenho do classificador atraves da funcao\n",
    "    #             relatorioDesempenho() criada anteriormente. Use a acuracia para decidir\n",
    "    #             o melhor parametro.            \n",
    "    #\n",
    "    \n",
    "    perf = []\n",
    "    \n",
    "    def kmax(i):\n",
    "        pval, idx = knn(Xval, X, Y, i)\n",
    "        cm = util.get_confusionMatrix(Yval, pval, [0,1])\n",
    "        results = util.relatorioDesempenho(cm, [0,1])\n",
    "        return results['acuracia']\n",
    "    \n",
    "    vkmax = np.vectorize(kmax, otypes=['float'])\n",
    "    perf = vkmax(K)\n",
    "\n",
    "    '''\n",
    "    for i in reg:\n",
    "        theta = treinamento(X, Y, i, iteracoes)\n",
    "        p = predicao(Xval, theta)\n",
    "        cm = get_confusionMatrix(Yval, p, [0,1])\n",
    "        results = relatorioDesempenho(cm, [0,1])\n",
    "        perf.append(results['acuracia'])\n",
    "    '''\n",
    "        \n",
    "    bestK = K[np.argmax(perf)]\n",
    "\n",
    "    ################################################################################## \n",
    "\n",
    "    return bestK\n",
    "\n",
    "# chama a função que faz a busca em grade\n",
    "bestRegularization = gridSearch(X_train_v, Y_train_v, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "Xk, Yk = Xfeatures[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "nFolds = 10\n",
    "classes = [0,1]\n",
    "iteracoes=1000\n",
    "folds = util.stratified_kfolds(Yk, nFolds, classes) \n",
    "\n",
    "k=1\n",
    "resultados=[]\n",
    "for train_index, test_index in folds:\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "        \n",
    "    totalFold = len(train_index)+len(test_index)\n",
    "\n",
    "    X_train, X_test = Xk[train_index, :], Xk[test_index, :];\n",
    "    Y_train, Y_test = Yk[train_index], Yk[test_index];\n",
    "    \n",
    "    # separa os dados de treinamento em treinamento e validacao\n",
    "    pTrain = 0.8\n",
    "    train_index_v, val_index = util.stratified_holdOut(Y_train, pTrain)\n",
    "\n",
    "    # chama a função que faz a busca em grade\n",
    "    bestK = gridSearch(X_train_v, Y_train_v, X_val, Y_val)\n",
    "\n",
    "    # executa o treinamento com o melhor parâmetro de regularização encontrado\n",
    "    #theta = treinamento(X_train,Y_train,bestRegularization,iteracoes)\n",
    "\n",
    "    # classifica os dados de teste\n",
    "    Y_pred,idx = knn(X_test, X_train, Y_train, bestK)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = util.get_confusionMatrix(Y_test, Y_pred, classes)\n",
    "\n",
    "    # Gera o relatório de desempenho\n",
    "    #print('\\n\\n\\n\\t'+\"=\"*50+'\\n\\tMelhor parametro de regularizacao: %1.6f' %bestRegularization)\n",
    "    print('\\n\\tResultado no fold atual usando o melhor parametro encontrado:')\n",
    "    auxResults = util.relatorioDesempenho(cm, classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults ) \n",
    "        \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nResultado final da classificação:')\n",
    "util.mediaFolds( resultados, classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
